Final Conclusion – Telco Customer Churn Project
==============================================

Scope
-----
This project operationalizes a churn analysis workflow on the IBM Telco Customer Churn dataset, including data preparation, EDA, encoding, multiple model evaluations, class imbalance handling with SMOTEENN, and result visualization.

Key Feature Insights (from EDA and model behavior)
--------------------------------------------------
- Tenure
  - Lower tenure (<= 12 months) is strongly associated with higher churn.
  - Higher tenure tends to reduce churn risk.
- Contract Type
  - Month-to-month contracts correlate with higher churn.
  - One-year and two-year contracts correlate with lower churn.
- Internet Service
  - Fiber optic subscribers tend to churn more than DSL in this dataset.
- Payment Method
  - Electronic check is associated with higher churn.
  - Automatic bank transfer/credit card methods often correlate with lower churn.
- Add-on Services
  - Having OnlineSecurity and/or TechSupport is associated with lower churn.
  - Lack of these services is associated with higher churn.
- Paperless Billing
  - Paperless billing shows a positive association with churn in this dataset.
- Charges
  - Very high monthly charges often increase churn risk.
  - Moderate charges tend to align with lower churn.

Best Model and Scores
---------------------
- Baseline (no resampling):
  - Best model: RandomForestClassifier
  - Test accuracy: ≈ 0.795
- With SMOTEENN (class imbalance mitigation):
  - Best model: KNeighborsClassifier (n_neighbors=3, weights='distance')
  - Test accuracy: ≈ 0.981–0.983 (varies slightly across runs)
  - Confusion matrix plots saved under `outputs/confusion_matrix.png`
- Best-model 20-sample check (held-out test subset):
  - 20-sample subset accuracy: 0.950
  - Details saved to `docs/BEST20_PREDICTIONS.txt`

Interpretation of Errors
------------------------
- Even the best model can make some mistakes due to:
  - Overlapping class patterns: some churn and non-churn profiles look very similar.
  - Proxy features: indicators like payment method or paperless billing shift probabilities but are not deterministic.
  - Resampling and split variance: SMOTEENN and train/test split introduce variance; KNN is sensitive to local neighborhoods.
  - Possible label noise and missing temporal context not captured by static features.
- These errors are acceptable within reason, given high test accuracy and the probabilistic nature of classification.

Recommendations
---------------
- Business Calibration
  - Tune decision thresholds based on costs of false positives vs false negatives.
  - Track precision, recall, F1, and ROC-AUC alongside accuracy for more balanced evaluation.
  - Calibrate probabilities if decisions use risk scores.
- Feature Engineering
  - Add more contextual features (e.g., recent support tickets, usage patterns, time since last plan change).
  - Consider interaction terms and non-linear transformations.
- Model Management
  - Persist the best model and implement monitoring for drift.
  - Re-train periodically with the latest data; re-evaluate threshold settings.
- Reporting and Ops
  - Export prediction explanations for business users (e.g., top contributing factors per prediction).
  - Version outputs (e.g., save `model_scores_baseline.png` and `model_scores_smoteenn.png` separately – already implemented).

Files of Interest
-----------------
- Main pipeline: `telco_churn.py`
- Best-model 20 predictions: `best_model_predict.py`
- Results and documentation:
  - `outputs/model_scores_baseline.png`
  - `outputs/model_scores_smoteenn.png`
  - `outputs/confusion_matrix.png`
  - `docs/PREDICTIONS.txt` (4 detailed examples + analysis)
  - `docs/BEST20_PREDICTIONS.txt` (20-sample run + accuracies)
  - `docs/RESULTS.txt`, `docs/STEP_BY_STEP.txt`, `docs/IMAGES_EXPLAINED.txt`, `docs/USAGE.txt`

Final Takeaway
--------------
- Tenure, contract type, internet service type, payment method, add-on security/support services, paperless billing, and charges are the most influential features for churn in this dataset.
- After addressing class imbalance with SMOTEENN, a simple distance-weighted KNN delivers high accuracy (~0.98) on the held-out test set, with a strong 20-sample subset performance (0.95). While a few errors remain inevitable due to overlapping patterns and proxy features, the model provides robust predictive performance suitable for practical churn-risk prioritization with appropriate business calibration.
